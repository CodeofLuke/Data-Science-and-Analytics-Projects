{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Function to generate random date of birth within a specified range\n",
    "def random_dob(start_date, end_date):\n",
    "    days = (end_date - start_date).days\n",
    "    random_days = random.randint(0, days)\n",
    "    return start_date + timedelta(days=random_days)\n",
    "\n",
    "# Sample categories list\n",
    "categories = ['Entertainment', 'Food', 'HealthFitness', 'Home', 'KidsPets', 'PersonalCare',\n",
    "              'Grocery', 'Miscellaneous', 'Shopping', 'Travel']\n",
    "\n",
    "# Generate 1000 random records for the dataset\n",
    "data = []\n",
    "for _ in range(1000):\n",
    "    year = random.randint(2010, 2022)\n",
    "    month = random.randint(1, 12)\n",
    "    HOM_tag = random.choice([1, 2])\n",
    "    HOM_total = random.uniform(100, 500)\n",
    "    gender = random.choice(['M', 'F'])\n",
    "    job = random.choice(['Engineer', 'Teacher', 'Doctor', 'Artist', 'Manager'])\n",
    "    dob = random_dob(datetime(1960, 1, 1), datetime(2005, 12, 31))\n",
    "    total_spending = random.uniform(500, 2000)\n",
    "    average_spending = total_spending / random.randint(10, 30)\n",
    "    most_freq_category = random.choice(categories)\n",
    "\n",
    "    row = [year, month, HOM_tag, HOM_total]\n",
    "    for category in categories:\n",
    "        subtotal = random.uniform(0, 200)\n",
    "        freq = random.randint(0, 10)\n",
    "        row.extend([subtotal, freq])\n",
    "    row.extend([HOM_total, gender, job])\n",
    "    row.extend([random.uniform(0, 200) for _ in range(len(categories) * 2)])\n",
    "    row.extend([dob, random.randint(1, 10), total_spending, average_spending, most_freq_category])\n",
    "    data.append(row)\n",
    "\n",
    "# Create a DataFrame from the generated data\n",
    "columns = ['year', 'month', 'HOM_tag', 'HOM_total']\n",
    "columns.extend([f'{category}' for category in categories])\n",
    "columns.extend([f'{category}_Freq' for category in categories])\n",
    "columns.extend(['next_HOM_total', 'gender', 'job'])\n",
    "columns.extend([f'{category}' for category in categories])\n",
    "columns.extend([f'{category}_Freq' for category in categories])\n",
    "columns.extend(['dob', 'Travel_Freq', 'Total_Spending', 'Average_Spending', 'Most_Frequent_Category'])\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "df.to_csv('sample_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "df = pd.read_csv('apriori.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any rows with missing values (NaN)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical columns to string, as Apriori requires string values\n",
    "df['gender'] = df['gender'].astype(str)\n",
    "df['job'] = df['job'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'dob' column to datetime type\n",
    "df['dob'] = pd.to_datetime(df['dob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'month' and 'HOM_tag' columns to object (string) type\n",
    "df['month'] = df['month'].astype(str)\n",
    "df['HOM_tag'] = df['HOM_tag'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of columns containing item categories\n",
    "category_columns = [col for col in df.columns if col.endswith('_Freq')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the item category columns to binary format (1 if frequency > 0, 0 otherwise)\n",
    "for col in category_columns:\n",
    "    df[col] = df[col].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LUKE MARK LEONA\\Lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Apriori algorithm to find frequent itemsets\n",
    "frequent_itemsets = apriori(df[category_columns], min_support=0.05, use_colnames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Association rules generation\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemsets:\n",
      "      support                                           itemsets\n",
      "0       1.000                               (Entertainment_Freq)\n",
      "1       0.913                                        (Food_Freq)\n",
      "2       1.000                               (HealthFitness_Freq)\n",
      "3       0.918                                        (Home_Freq)\n",
      "4       1.000                                    (KidsPets_Freq)\n",
      "...       ...                                                ...\n",
      "1018    0.669  (Food_Freq, Entertainment_Freq, Grocery_Freq, ...\n",
      "1019    0.612  (Food_Freq, Entertainment_Freq, Grocery_Freq, ...\n",
      "1020    0.671  (Entertainment_Freq, Grocery_Freq, Shopping_Fr...\n",
      "1021    0.612  (Food_Freq, Grocery_Freq, Shopping_Freq, KidsP...\n",
      "1022    0.612  (Food_Freq, Entertainment_Freq, Grocery_Freq, ...\n",
      "\n",
      "[1023 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display frequent itemsets\n",
    "print(\"Frequent Itemsets:\")\n",
    "print(frequent_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000</td>\n",
       "      <td>(Entertainment_Freq)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.913</td>\n",
       "      <td>(Food_Freq)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000</td>\n",
       "      <td>(HealthFitness_Freq)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.918</td>\n",
       "      <td>(Home_Freq)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>(KidsPets_Freq)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>0.669</td>\n",
       "      <td>(Food_Freq, Entertainment_Freq, Grocery_Freq, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>0.612</td>\n",
       "      <td>(Food_Freq, Entertainment_Freq, Grocery_Freq, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>0.671</td>\n",
       "      <td>(Entertainment_Freq, Grocery_Freq, Shopping_Fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>0.612</td>\n",
       "      <td>(Food_Freq, Grocery_Freq, Shopping_Freq, KidsP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>0.612</td>\n",
       "      <td>(Food_Freq, Entertainment_Freq, Grocery_Freq, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1023 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      support                                           itemsets\n",
       "0       1.000                               (Entertainment_Freq)\n",
       "1       0.913                                        (Food_Freq)\n",
       "2       1.000                               (HealthFitness_Freq)\n",
       "3       0.918                                        (Home_Freq)\n",
       "4       1.000                                    (KidsPets_Freq)\n",
       "...       ...                                                ...\n",
       "1018    0.669  (Food_Freq, Entertainment_Freq, Grocery_Freq, ...\n",
       "1019    0.612  (Food_Freq, Entertainment_Freq, Grocery_Freq, ...\n",
       "1020    0.671  (Entertainment_Freq, Grocery_Freq, Shopping_Fr...\n",
       "1021    0.612  (Food_Freq, Grocery_Freq, Shopping_Freq, KidsP...\n",
       "1022    0.612  (Food_Freq, Entertainment_Freq, Grocery_Freq, ...\n",
       "\n",
       "[1023 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Association Rules:\n",
      "                antecedents   \n",
      "0               (Food_Freq)  \\\n",
      "1      (Entertainment_Freq)   \n",
      "2      (HealthFitness_Freq)   \n",
      "3      (Entertainment_Freq)   \n",
      "4               (Home_Freq)   \n",
      "...                     ...   \n",
      "56997         (Travel_Freq)   \n",
      "56998           (Home_Freq)   \n",
      "56999  (Miscellaneous_Freq)   \n",
      "57000  (HealthFitness_Freq)   \n",
      "57001   (PersonalCare_Freq)   \n",
      "\n",
      "                                             consequents  antecedent support   \n",
      "0                                   (Entertainment_Freq)               0.913  \\\n",
      "1                                            (Food_Freq)               1.000   \n",
      "2                                   (Entertainment_Freq)               1.000   \n",
      "3                                   (HealthFitness_Freq)               1.000   \n",
      "4                                   (Entertainment_Freq)               0.918   \n",
      "...                                                  ...                 ...   \n",
      "56997  (Food_Freq, Entertainment_Freq, Grocery_Freq, ...               0.902   \n",
      "56998  (Food_Freq, Entertainment_Freq, Grocery_Freq, ...               0.918   \n",
      "56999  (Food_Freq, Entertainment_Freq, Grocery_Freq, ...               0.890   \n",
      "57000  (Food_Freq, Entertainment_Freq, Grocery_Freq, ...               1.000   \n",
      "57001  (Food_Freq, Entertainment_Freq, Grocery_Freq, ...               0.919   \n",
      "\n",
      "       consequent support  support  confidence      lift  leverage   \n",
      "0                   1.000    0.913    1.000000  1.000000  0.000000  \\\n",
      "1                   0.913    0.913    0.913000  1.000000  0.000000   \n",
      "2                   1.000    1.000    1.000000  1.000000  0.000000   \n",
      "3                   1.000    1.000    1.000000  1.000000  0.000000   \n",
      "4                   1.000    0.918    1.000000  1.000000  0.000000   \n",
      "...                   ...      ...         ...       ...       ...   \n",
      "56997               0.674    0.612    0.678492  1.006665  0.004052   \n",
      "56998               0.669    0.612    0.666667  0.996512 -0.002142   \n",
      "56999               0.699    0.612    0.687640  0.983749 -0.010110   \n",
      "57000               0.612    0.612    0.612000  1.000000  0.000000   \n",
      "57001               0.669    0.612    0.665941  0.995428 -0.002811   \n",
      "\n",
      "       conviction  zhangs_metric  \n",
      "0             inf       0.000000  \n",
      "1        1.000000       0.000000  \n",
      "2             inf       0.000000  \n",
      "3             inf       0.000000  \n",
      "4             inf       0.000000  \n",
      "...           ...            ...  \n",
      "56997    1.013972       0.067560  \n",
      "56998    0.993000      -0.040936  \n",
      "56999    0.963633      -0.130570  \n",
      "57000    1.000000       0.000000  \n",
      "57001    0.990844      -0.053662  \n",
      "\n",
      "[57002 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display association rules\n",
    "print(\"\\nAssociation Rules:\")\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save frequent itemsets to a new CSV file\n",
    "frequent_itemsets.to_csv('frequent_itemsets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save association rules to a new CSV file\n",
    "rules.to_csv('association_rules.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             antecedents   \n",
      "0                               frozenset({'Food_Freq'})  \\\n",
      "2                      frozenset({'HealthFitness_Freq'})   \n",
      "3                      frozenset({'Entertainment_Freq'})   \n",
      "4                               frozenset({'Home_Freq'})   \n",
      "6                           frozenset({'KidsPets_Freq'})   \n",
      "...                                                  ...   \n",
      "56256  frozenset({'Food_Freq', 'Grocery_Freq', 'Trave...   \n",
      "56271  frozenset({'Food_Freq', 'Shopping_Freq', 'Trav...   \n",
      "56276  frozenset({'Food_Freq', 'KidsPets_Freq', 'Trav...   \n",
      "56280  frozenset({'Food_Freq', 'Travel_Freq', 'Home_F...   \n",
      "56487  frozenset({'Food_Freq', 'Travel_Freq', 'Home_F...   \n",
      "\n",
      "                                             consequents  antecedent support   \n",
      "0                      frozenset({'Entertainment_Freq'})               0.913  \\\n",
      "2                      frozenset({'Entertainment_Freq'})               1.000   \n",
      "3                      frozenset({'HealthFitness_Freq'})               1.000   \n",
      "4                      frozenset({'Entertainment_Freq'})               0.918   \n",
      "6                      frozenset({'Entertainment_Freq'})               1.000   \n",
      "...                                                  ...                 ...   \n",
      "56256  frozenset({'Shopping_Freq', 'KidsPets_Freq', '...               0.612   \n",
      "56271  frozenset({'Grocery_Freq', 'KidsPets_Freq', 'H...               0.612   \n",
      "56276  frozenset({'Grocery_Freq', 'Shopping_Freq', 'H...               0.612   \n",
      "56280  frozenset({'Grocery_Freq', 'KidsPets_Freq', 'S...               0.612   \n",
      "56487  frozenset({'Entertainment_Freq', 'Grocery_Freq...               0.612   \n",
      "\n",
      "       consequent support  support  confidence  lift  leverage  conviction   \n",
      "0                     1.0    0.913         1.0   1.0       0.0         inf  \\\n",
      "2                     1.0    1.000         1.0   1.0       0.0         inf   \n",
      "3                     1.0    1.000         1.0   1.0       0.0         inf   \n",
      "4                     1.0    0.918         1.0   1.0       0.0         inf   \n",
      "6                     1.0    1.000         1.0   1.0       0.0         inf   \n",
      "...                   ...      ...         ...   ...       ...         ...   \n",
      "56256                 1.0    0.612         1.0   1.0       0.0         inf   \n",
      "56271                 1.0    0.612         1.0   1.0       0.0         inf   \n",
      "56276                 1.0    0.612         1.0   1.0       0.0         inf   \n",
      "56280                 1.0    0.612         1.0   1.0       0.0         inf   \n",
      "56487                 1.0    0.612         1.0   1.0       0.0         inf   \n",
      "\n",
      "       zhangs_metric  \n",
      "0                0.0  \n",
      "2                0.0  \n",
      "3                0.0  \n",
      "4                0.0  \n",
      "6                0.0  \n",
      "...              ...  \n",
      "56256            0.0  \n",
      "56271            0.0  \n",
      "56276            0.0  \n",
      "56280            0.0  \n",
      "56487            0.0  \n",
      "\n",
      "[6721 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the association rules from the CSV file\n",
    "association_rules = pd.read_csv('association_rules.csv')\n",
    "\n",
    "# Define the thresholds for the metrics to consider significant\n",
    "min_confidence = 0.95\n",
    "min_lift = 1.0\n",
    "min_conviction = 1.0\n",
    "\n",
    "# Filter the association rules based on the defined thresholds\n",
    "significant_rules = association_rules[\n",
    "    (association_rules['confidence'] >= min_confidence) &\n",
    "    (association_rules['lift'] >= min_lift) &\n",
    "    (association_rules['conviction'] >= min_conviction)\n",
    "]\n",
    "\n",
    "# Display the filtered significant association rules\n",
    "print(significant_rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered significant association rules to a new CSV file\n",
    "significant_rules.to_csv('significant_rules.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the association rules from the CSV file\n",
    "association_rules = pd.read_csv('association_rules.csv')\n",
    "\n",
    "# Define the thresholds for the metrics to consider significant\n",
    "min_confidence = 0.90\n",
    "min_lift = 1.0\n",
    "min_conviction = 1.0\n",
    "\n",
    "# Filter the association rules based on the defined thresholds\n",
    "significant_rules = association_rules[\n",
    "    (association_rules['confidence'] >= min_confidence) &\n",
    "    (association_rules['lift'] >= min_lift) &\n",
    "    (association_rules['conviction'] >= min_conviction)\n",
    "]\n",
    "\n",
    "# Sort the significant_rules DataFrame by a specific metric, e.g., confidence, in descending order\n",
    "sorted_rules = significant_rules.sort_values(by='confidence', ascending=False)\n",
    "\n",
    "# Filter the top 20 significant rules based on the chosen metric (confidence in this example)\n",
    "top_20_significant_rules = sorted_rules.head(20)\n",
    "\n",
    "# Save the top 20 significant association rules to a new CSV file\n",
    "top_20_significant_rules.to_csv('top_20_significant_rules.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the association rules from the CSV file\n",
    "association_rules = pd.read_csv('association_rules.csv')\n",
    "\n",
    "# Define the thresholds for the metrics to consider significant\n",
    "min_confidence = 0.9\n",
    "min_lift = 1.0\n",
    "min_conviction = 1.0\n",
    "\n",
    "# Filter the association rules based on the defined thresholds and length of items in antecedents and consequents\n",
    "filtered_rules = association_rules[\n",
    "    (association_rules['confidence'] >= min_confidence) &\n",
    "    (association_rules['lift'] >= min_lift) &\n",
    "    (association_rules['conviction'] >= min_conviction) &\n",
    "    ((association_rules['antecedents'].apply(lambda x: len(eval(x))) >=1) &\n",
    "     (association_rules['antecedents'].apply(lambda x: len(eval(x))) <= 2)) &\n",
    "    ((association_rules['consequents'].apply(lambda x: len(eval(x))) >= 1) &\n",
    "     (association_rules['consequents'].apply(lambda x: len(eval(x))) <= 2))\n",
    "]\n",
    "\n",
    "# Sort the filtered_rules DataFrame based on a specific metric, e.g., confidence, in descending order\n",
    "sorted_rules = filtered_rules.sort_values(by='confidence', ascending=False)\n",
    "\n",
    "# Filter the top 20 significant rules with 2 to 3 combinations of categories\n",
    "top_20_significant_rules = sorted_rules.head(20)\n",
    "\n",
    "# Save the top 20 significant association rules to a new CSV file\n",
    "top_20_significant_rules.to_csv('top_20_significant_rules_2to3_categories.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
